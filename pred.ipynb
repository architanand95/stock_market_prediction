{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b9e84a",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-11-04T12:21:07.640661Z",
     "iopub.status.busy": "2023-11-04T12:21:07.640014Z",
     "iopub.status.idle": "2023-11-04T12:21:09.817616Z",
     "shell.execute_reply": "2023-11-04T12:21:09.816688Z"
    },
    "papermill": {
     "duration": 2.193165,
     "end_time": "2023-11-04T12:21:09.820200",
     "exception": false,
     "start_time": "2023-11-04T12:21:07.627035",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef632e09",
   "metadata": {
    "papermill": {
     "duration": 0.010298,
     "end_time": "2023-11-04T12:21:09.841437",
     "exception": false,
     "start_time": "2023-11-04T12:21:09.831139",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Sarimax Using Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6811083c",
   "metadata": {
    "papermill": {
     "duration": 0.010654,
     "end_time": "2023-11-04T12:21:09.862793",
     "exception": false,
     "start_time": "2023-11-04T12:21:09.852139",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The code loads two CSV files into Pandas DataFrames, parsing the 'Date' column as datetime objects, and then sorts both DataFrames by the 'Date' column. The .head() method displays the first few rows of the sorted 'df' DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccaee1da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T12:21:09.886900Z",
     "iopub.status.busy": "2023-11-04T12:21:09.886119Z",
     "iopub.status.idle": "2023-11-04T12:21:09.944233Z",
     "shell.execute_reply": "2023-11-04T12:21:09.943072Z"
    },
    "papermill": {
     "duration": 0.073319,
     "end_time": "2023-11-04T12:21:09.946934",
     "exception": false,
     "start_time": "2023-11-04T12:21:09.873615",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv', parse_dates=['Date'])\n",
    "test=pd.read_csv('test.csv',parse_dates=['Date'])\n",
    "df = df.sort_values(by='Date')\n",
    "test = test.sort_values(by='Date')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b25b6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T12:21:09.971615Z",
     "iopub.status.busy": "2023-11-04T12:21:09.971185Z",
     "iopub.status.idle": "2023-11-04T12:21:12.099400Z",
     "shell.execute_reply": "2023-11-04T12:21:12.097807Z"
    },
    "papermill": {
     "duration": 2.144136,
     "end_time": "2023-11-04T12:21:12.102776",
     "exception": false,
     "start_time": "2023-11-04T12:21:09.958640",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#acf\n",
    "import statsmodels.api as sm    #from the below graph i see a=1 one spike above threshold .\n",
    "import matplotlib.pyplot as plt\n",
    "sm.graphics.tsa.plot_acf(df['Close'], lags=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528537e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T12:21:12.131345Z",
     "iopub.status.busy": "2023-11-04T12:21:12.130924Z",
     "iopub.status.idle": "2023-11-04T12:21:12.485432Z",
     "shell.execute_reply": "2023-11-04T12:21:12.484204Z"
    },
    "papermill": {
     "duration": 0.371014,
     "end_time": "2023-11-04T12:21:12.488211",
     "exception": false,
     "start_time": "2023-11-04T12:21:12.117197",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#pacf\n",
    "import statsmodels.api as sm  #here q = 1 as one spike above\n",
    "import matplotlib.pyplot as plt\n",
    "sm.graphics.tsa.plot_pacf(df['Close'], lags=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1c1c88",
   "metadata": {
    "papermill": {
     "duration": 0.012029,
     "end_time": "2023-11-04T12:21:12.512435",
     "exception": false,
     "start_time": "2023-11-04T12:21:12.500406",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Since pacf and acf graphs above are inconclusive we use pmdarima library too determine p, d , q values ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e62ec0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T12:21:12.538466Z",
     "iopub.status.busy": "2023-11-04T12:21:12.537755Z",
     "iopub.status.idle": "2023-11-04T12:21:29.003275Z",
     "shell.execute_reply": "2023-11-04T12:21:29.001443Z"
    },
    "papermill": {
     "duration": 16.482158,
     "end_time": "2023-11-04T12:21:29.006620",
     "exception": false,
     "start_time": "2023-11-04T12:21:12.524462",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install pmdarima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb6b037",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T12:21:29.036309Z",
     "iopub.status.busy": "2023-11-04T12:21:29.035862Z",
     "iopub.status.idle": "2023-11-04T12:21:29.621595Z",
     "shell.execute_reply": "2023-11-04T12:21:29.620393Z"
    },
    "papermill": {
     "duration": 0.604294,
     "end_time": "2023-11-04T12:21:29.624974",
     "exception": false,
     "start_time": "2023-11-04T12:21:29.020680",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from pmdarima.arima import auto_arima"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcffa6e4",
   "metadata": {
    "papermill": {
     "duration": 0.013873,
     "end_time": "2023-11-04T12:21:29.653303",
     "exception": false,
     "start_time": "2023-11-04T12:21:29.639430",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Two new features, 'price_change' and 'price_ratio,' are added to the 'df' DataFrame, representing the price change (Close - Open) and price ratio (Close / Open) for each row, respectively, which can provide insights into price movements and trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6de93cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T12:21:29.683638Z",
     "iopub.status.busy": "2023-11-04T12:21:29.682631Z",
     "iopub.status.idle": "2023-11-04T12:21:29.691991Z",
     "shell.execute_reply": "2023-11-04T12:21:29.691100Z"
    },
    "papermill": {
     "duration": 0.028188,
     "end_time": "2023-11-04T12:21:29.694864",
     "exception": false,
     "start_time": "2023-11-04T12:21:29.666676",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#ADDING FEATURES\n",
    "df['price_change'] = df['Close'] - df['Open']\n",
    "df['price_ratio'] = df['Close'] / df['Open']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139c93ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T12:21:29.723387Z",
     "iopub.status.busy": "2023-11-04T12:21:29.722962Z",
     "iopub.status.idle": "2023-11-04T12:21:29.732394Z",
     "shell.execute_reply": "2023-11-04T12:21:29.730929Z"
    },
    "papermill": {
     "duration": 0.02705,
     "end_time": "2023-11-04T12:21:29.735306",
     "exception": false,
     "start_time": "2023-11-04T12:21:29.708256",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['Open_EMA'] = df['Open'].ewm(span = 3, adjust = False).mean()\n",
    "df['Volume_EMA'] =df['Volume'].ewm(span = 3, adjust = False).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe996b62",
   "metadata": {
    "papermill": {
     "duration": 0.012992,
     "end_time": "2023-11-04T12:21:29.763339",
     "exception": false,
     "start_time": "2023-11-04T12:21:29.750347",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Lag features for 'Open' and 'Volume' columns are created with two time-step lags, providing historical data on the previous two days for these attributes. Backfill (bfill) is applied to handle missing values in the lag features, ensuring continuity in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a9c0cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T12:21:29.793532Z",
     "iopub.status.busy": "2023-11-04T12:21:29.792982Z",
     "iopub.status.idle": "2023-11-04T12:21:29.814324Z",
     "shell.execute_reply": "2023-11-04T12:21:29.813221Z"
    },
    "papermill": {
     "duration": 0.039943,
     "end_time": "2023-11-04T12:21:29.817132",
     "exception": false,
     "start_time": "2023-11-04T12:21:29.777189",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create lag features for the 'Open' column\n",
    "df['open_lag_1'] = df['Open'].shift(1)\n",
    "df['open_lag_2'] = df['Open'].shift(2)\n",
    "\n",
    "# Use backfill (bfill) to handle NaN values in the 'Open' lag features\n",
    "df['open_lag_1'].fillna(method='bfill', inplace=True)\n",
    "df['open_lag_2'].fillna(method='bfill', inplace=True)\n",
    "\n",
    "# Create lag features for the 'Volume' column\n",
    "df['vol_lag_1'] = df['Volume'].shift(1)\n",
    "df['vol_lag_2'] = df['Volume'].shift(2)\n",
    "\n",
    "# Use backfill (bfill) to handle NaN values in the 'Volume' lag features\n",
    "df['vol_lag_1'].fillna(method='bfill', inplace=True)\n",
    "df['vol_lag_2'].fillna(method='bfill', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30cf0c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T12:21:29.845370Z",
     "iopub.status.busy": "2023-11-04T12:21:29.844539Z",
     "iopub.status.idle": "2023-11-04T12:21:29.867808Z",
     "shell.execute_reply": "2023-11-04T12:21:29.866642Z"
    },
    "papermill": {
     "duration": 0.040024,
     "end_time": "2023-11-04T12:21:29.870338",
     "exception": false,
     "start_time": "2023-11-04T12:21:29.830314",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910f6b17",
   "metadata": {
    "papermill": {
     "duration": 0.013398,
     "end_time": "2023-11-04T12:21:29.897967",
     "exception": false,
     "start_time": "2023-11-04T12:21:29.884569",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "A subset of columns from the 'df' DataFrame is selected to create a new DataFrame 'features' that includes attributes like 'Open,' 'Volume,' 'Open_EMA,' 'Volume_EMA,' and lag features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1d101d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T12:21:29.927549Z",
     "iopub.status.busy": "2023-11-04T12:21:29.927076Z",
     "iopub.status.idle": "2023-11-04T12:21:29.938993Z",
     "shell.execute_reply": "2023-11-04T12:21:29.937725Z"
    },
    "papermill": {
     "duration": 0.02949,
     "end_time": "2023-11-04T12:21:29.941577",
     "exception": false,
     "start_time": "2023-11-04T12:21:29.912087",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "features = df[['Open', 'Volume', 'Open_EMA', 'Volume_EMA', 'open_lag_1', 'open_lag_2', 'vol_lag_1', 'vol_lag_2']]\n",
    "target = df['Close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db72398",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T12:21:29.970433Z",
     "iopub.status.busy": "2023-11-04T12:21:29.969992Z",
     "iopub.status.idle": "2023-11-04T12:21:29.976440Z",
     "shell.execute_reply": "2023-11-04T12:21:29.975181Z"
    },
    "papermill": {
     "duration": 0.023663,
     "end_time": "2023-11-04T12:21:29.978868",
     "exception": false,
     "start_time": "2023-11-04T12:21:29.955205",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "train_size = int(len(df) * 0.8)  # 80% for training\n",
    "train_data, test_data = df[:train_size], df[train_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2baf5d4",
   "metadata": {
    "papermill": {
     "duration": 0.014168,
     "end_time": "2023-11-04T12:21:30.007641",
     "exception": false,
     "start_time": "2023-11-04T12:21:29.993473",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "This code performs a grid search to find the optimal (p, d, q, P, D, Q, s) parameters for a SARIMA model using AIC values, iterating through various combinations and storing AIC values in a dictionary. The sorted dictionary provides the parameter combinations with the lowest AIC values, helping identify the best-fitting SARIMA model for the given time series data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b731f40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T12:21:30.038000Z",
     "iopub.status.busy": "2023-11-04T12:21:30.037546Z",
     "iopub.status.idle": "2023-11-04T12:22:48.556194Z",
     "shell.execute_reply": "2023-11-04T12:22:48.555026Z"
    },
    "papermill": {
     "duration": 78.536875,
     "end_time": "2023-11-04T12:22:48.559136",
     "exception": false,
     "start_time": "2023-11-04T12:21:30.022261",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#grid search for sarimax optimal values\n",
    "import warnings\n",
    "import itertools\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define the range of p, d, q, P, D, Q, and s values\n",
    "p = d = q = range(0, 3)  \n",
    "P = D = Q = range(0, 2)  \n",
    "s = 12  \n",
    "\n",
    "pdq = list(itertools.product(p, d, q))\n",
    "seasonal_pdq = list(itertools.product(P, D, Q, [s]))\n",
    "\n",
    "# empty dictionary to store AIC values for each model\n",
    "store = {}\n",
    "\n",
    "# Iterate through all (p, d, q, P, D, Q, s) combinations\n",
    "for param in pdq:\n",
    "    for param_seasonal in seasonal_pdq:\n",
    "        try:\n",
    "            model_sarima = sm.tsa.SARIMAX(train_data['Close'], order=param, seasonal_order=param_seasonal, enforce_stationarity=False, enforce_invertibility=False)\n",
    "            model_sarima_fit = model_sarima.fit()\n",
    "            store[(param, param_seasonal)] = model_sarima_fit.aic\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "# Sort the dictionary by AIC values\n",
    "sorted_dict = dict(sorted(store.items(), key=lambda item: item[1]))\n",
    "\n",
    "# Print the sorted dictionary\n",
    "print(sorted_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea73c79f",
   "metadata": {
    "papermill": {
     "duration": 0.058653,
     "end_time": "2023-11-04T12:22:48.744663",
     "exception": false,
     "start_time": "2023-11-04T12:22:48.686010",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This code fits a SARIMAX model with exogenous variables on training data and uses it to make predictions on the testing data. It calculates and prints evaluation metrics like SMAPE, RMSE, and R2 Score to assess the model's performance in forecasting the 'Close' prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318d8616",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T12:22:48.864677Z",
     "iopub.status.busy": "2023-11-04T12:22:48.864220Z",
     "iopub.status.idle": "2023-11-04T12:22:52.084327Z",
     "shell.execute_reply": "2023-11-04T12:22:52.083205Z"
    },
    "papermill": {
     "duration": 3.284823,
     "end_time": "2023-11-04T12:22:52.088388",
     "exception": false,
     "start_time": "2023-11-04T12:22:48.803565",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from math import sqrt\n",
    "\n",
    "endog = train_data['Close']\n",
    "exog = sm.add_constant(train_data[['Open', 'Volume', 'Open_EMA', 'Volume_EMA', 'open_lag_1', 'open_lag_2', 'vol_lag_1', 'vol_lag_2']] )\n",
    "\n",
    "\n",
    "p, d, q = 1, 1, 2\n",
    "P, D, Q, S = 0, 1, 1, 12\n",
    "\n",
    "# Create the SARIMAX model\n",
    "mod = sm.tsa.statespace.SARIMAX(endog=train_data['Close'], exog=exog[:train_size], order=(p, d, q), seasonal_order=(P, D, Q, S))\n",
    "\n",
    "# Fit the SARIMAX model on the training data\n",
    "model_fit = mod.fit(disp=False)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "test_exog = sm.add_constant(test_data[['Open', 'Volume', 'Open_EMA', 'Volume_EMA', 'open_lag_1', 'open_lag_2', 'vol_lag_1', 'vol_lag_2']])\n",
    "predictions = model_fit.predict(start=len(train_data), end=len(train_data) + len(test_data) - 1, exog=test_exog)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "smape = np.mean(np.abs(predictions - test_data['Close']) / (np.abs(predictions) + np.abs(test_data['Close'])))\n",
    "#smape = np.mean(np.abs(y_pred - y_true) / (np.abs(y_pred) + np.abs(y_true)))\n",
    "rmse = sqrt(mean_squared_error(test_data['Close'], predictions))\n",
    "r2 = r2_score(test_data['Close'], predictions)\n",
    "\n",
    "# Display evaluation metrics\n",
    "print(\"SMAPE:\",smape)\n",
    "print(\"RMSE:\",rmse)\n",
    "print(\"R2 Score:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb781818",
   "metadata": {
    "papermill": {
     "duration": 0.059297,
     "end_time": "2023-11-04T12:22:52.233690",
     "exception": false,
     "start_time": "2023-11-04T12:22:52.174393",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "This code creates a line plot to visually compare the actual 'Close' prices in the test data with the predicted values, allowing for a visual assessment of the model's performance. The plot shows how closely the model's predictions align with the actual data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895069bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T12:22:52.353930Z",
     "iopub.status.busy": "2023-11-04T12:22:52.353553Z",
     "iopub.status.idle": "2023-11-04T12:22:52.699421Z",
     "shell.execute_reply": "2023-11-04T12:22:52.698185Z"
    },
    "papermill": {
     "duration": 0.409265,
     "end_time": "2023-11-04T12:22:52.702109",
     "exception": false,
     "start_time": "2023-11-04T12:22:52.292844",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_data['Close'].plot()\n",
    "predictions.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1f8cc1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T12:22:52.825497Z",
     "iopub.status.busy": "2023-11-04T12:22:52.824402Z",
     "iopub.status.idle": "2023-11-04T12:22:52.836178Z",
     "shell.execute_reply": "2023-11-04T12:22:52.835010Z"
    },
    "papermill": {
     "duration": 0.076049,
     "end_time": "2023-11-04T12:22:52.838526",
     "exception": false,
     "start_time": "2023-11-04T12:22:52.762477",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82939ae0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T12:22:52.962056Z",
     "iopub.status.busy": "2023-11-04T12:22:52.961646Z",
     "iopub.status.idle": "2023-11-04T12:22:52.969115Z",
     "shell.execute_reply": "2023-11-04T12:22:52.968017Z"
    },
    "papermill": {
     "duration": 0.072489,
     "end_time": "2023-11-04T12:22:52.971528",
     "exception": false,
     "start_time": "2023-11-04T12:22:52.899039",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test['Open_EMA'] = test['Open'].ewm(span = 3, adjust = False).mean()\n",
    "test['Volume_EMA']= test['Volume'].ewm(span = 3, adjust = False).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0419e133",
   "metadata": {
    "papermill": {
     "duration": 0.063824,
     "end_time": "2023-11-04T12:22:53.096733",
     "exception": false,
     "start_time": "2023-11-04T12:22:53.032909",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Similar to the previous code for the training data, this code creates lag features for the 'Open' and 'Volume' columns in the 'test' DataFrame, providing historical data from the previous two days. Backfill (bfill) is used to handle missing values in these lag features, ensuring consistency in the dataset for testing and prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c28e1ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T12:22:53.238950Z",
     "iopub.status.busy": "2023-11-04T12:22:53.238522Z",
     "iopub.status.idle": "2023-11-04T12:22:53.251602Z",
     "shell.execute_reply": "2023-11-04T12:22:53.250540Z"
    },
    "papermill": {
     "duration": 0.089933,
     "end_time": "2023-11-04T12:22:53.254051",
     "exception": false,
     "start_time": "2023-11-04T12:22:53.164118",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create lag features for the 'Open' column\n",
    "test['open_lag_1'] = test['Open'].shift(1)\n",
    "test['open_lag_2'] = test['Open'].shift(2)\n",
    "\n",
    "# Use backfill (bfill) to handle NaN values in the 'Open' lag features\n",
    "test['open_lag_1'].fillna(method='bfill', inplace=True)\n",
    "test['open_lag_2'].fillna(method='bfill', inplace=True)\n",
    "\n",
    "# Create lag features for the 'Volume' column\n",
    "test['vol_lag_1'] = test['Volume'].shift(1)\n",
    "test['vol_lag_2'] = test['Volume'].shift(2)\n",
    "\n",
    "# Use backfill (bfill) to handle NaN values in the 'Volume' lag features\n",
    "test['vol_lag_1'].fillna(method='bfill', inplace=True)\n",
    "test['vol_lag_2'].fillna(method='bfill', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28754161",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T12:22:53.377964Z",
     "iopub.status.busy": "2023-11-04T12:22:53.376831Z",
     "iopub.status.idle": "2023-11-04T12:22:53.396075Z",
     "shell.execute_reply": "2023-11-04T12:22:53.394928Z"
    },
    "papermill": {
     "duration": 0.083981,
     "end_time": "2023-11-04T12:22:53.398687",
     "exception": false,
     "start_time": "2023-11-04T12:22:53.314706",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db56ee0",
   "metadata": {
    "papermill": {
     "duration": 0.06092,
     "end_time": "2023-11-04T12:22:53.522059",
     "exception": false,
     "start_time": "2023-11-04T12:22:53.461139",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "This code prepares exogenous variables for the test dataset and uses the previously trained SARIMAX model ('model_fit') to make predictions for the 'Close' prices in the test data, incorporating the exogenous features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd45e6aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T12:22:53.649790Z",
     "iopub.status.busy": "2023-11-04T12:22:53.649098Z",
     "iopub.status.idle": "2023-11-04T12:22:53.661672Z",
     "shell.execute_reply": "2023-11-04T12:22:53.660546Z"
    },
    "papermill": {
     "duration": 0.07911,
     "end_time": "2023-11-04T12:22:53.664428",
     "exception": false,
     "start_time": "2023-11-04T12:22:53.585318",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "t_exog = sm.add_constant(test[['Open', 'Volume', 'Open_EMA', 'Volume_EMA', 'open_lag_1', 'open_lag_2', 'vol_lag_1', 'vol_lag_2']])\n",
    "p = model_fit.predict(steps=len(test), exog=t_exog) #training the model on dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e973f6b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T12:22:53.793432Z",
     "iopub.status.busy": "2023-11-04T12:22:53.792402Z",
     "iopub.status.idle": "2023-11-04T12:22:53.800752Z",
     "shell.execute_reply": "2023-11-04T12:22:53.799930Z"
    },
    "papermill": {
     "duration": 0.075324,
     "end_time": "2023-11-04T12:22:53.802840",
     "exception": false,
     "start_time": "2023-11-04T12:22:53.727516",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0663609a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T12:22:53.928939Z",
     "iopub.status.busy": "2023-11-04T12:22:53.928157Z",
     "iopub.status.idle": "2023-11-04T12:22:53.934219Z",
     "shell.execute_reply": "2023-11-04T12:22:53.933263Z"
    },
    "papermill": {
     "duration": 0.071743,
     "end_time": "2023-11-04T12:22:53.936613",
     "exception": false,
     "start_time": "2023-11-04T12:22:53.864870",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test['Close']=p #final predictions are saved here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e720d08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T12:22:54.061477Z",
     "iopub.status.busy": "2023-11-04T12:22:54.060730Z",
     "iopub.status.idle": "2023-11-04T12:22:54.087446Z",
     "shell.execute_reply": "2023-11-04T12:22:54.086525Z"
    },
    "papermill": {
     "duration": 0.091324,
     "end_time": "2023-11-04T12:22:54.089541",
     "exception": false,
     "start_time": "2023-11-04T12:22:53.998217",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c57b16b",
   "metadata": {
    "papermill": {
     "duration": 0.063547,
     "end_time": "2023-11-04T12:22:54.215439",
     "exception": false,
     "start_time": "2023-11-04T12:22:54.151892",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This code performs binary classification on financial data using a Voting Classifier that combines Random Forest and XGBoost models to predict trading strategies. It then applies the trained model to a test dataset, saves the predictions, and creates a submission CSV file for further analysis or competition submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108d4c19",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T12:22:54.341712Z",
     "iopub.status.busy": "2023-11-04T12:22:54.340940Z",
     "iopub.status.idle": "2023-11-04T12:22:55.322117Z",
     "shell.execute_reply": "2023-11-04T12:22:55.320913Z"
    },
    "papermill": {
     "duration": 1.046951,
     "end_time": "2023-11-04T12:22:55.324963",
     "exception": false,
     "start_time": "2023-11-04T12:22:54.278012",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Assuming 'df' contains your dataset\n",
    "\n",
    "# Feature engineering - Adding new features based on existing ones\n",
    "df['Open_Close_diff'] = df['Open'] - df['Close']  # Difference between Open and Close\n",
    "df['Volume_squared'] = df['Volume'] ** 2  # Volume squared\n",
    "\n",
    "# Encoding the 'Strategy' column\n",
    "label_encoder = LabelEncoder()\n",
    "df['Strategy'] = label_encoder.fit_transform(df['Strategy'])\n",
    "\n",
    "# Splitting the data into features and target variable\n",
    "X = df[['Open', 'Close', 'Volume', 'Open_Close_diff', 'Volume_squared']]\n",
    "y = df['Strategy']\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=40)\n",
    "\n",
    "# Initializing Random Forest and XGBoost classifiers\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)  # Random Forest Classifier\n",
    "xgb_classifier = XGBClassifier(n_estimators=100, objective='multi:softmax', num_class=3)  # XGBoost Classifier\n",
    "\n",
    "# Creating a Voting Classifier that combines Random Forest and XGBoost classifiers\n",
    "voting_classifier = VotingClassifier(estimators=[('rf', rf_classifier), ('xgb', xgb_classifier)], voting='soft')\n",
    "\n",
    "# Fitting the Voting Classifier on the training data\n",
    "voting_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions on the test data\n",
    "y_pred = voting_classifier.predict(X_test)\n",
    "\n",
    "# Inverse transforming the encoded predictions to their original labels\n",
    "y_pred = label_encoder.inverse_transform(y_pred)\n",
    "\n",
    "# Assuming 'test' is another DataFrame for which you want predictions\n",
    "# Feature engineering for the test data\n",
    "test['Open_Close_diff'] = test['Open'] - test['Close']\n",
    "test['Volume_squared'] = test['Volume'] ** 2\n",
    "\n",
    "# Selecting features for the test data\n",
    "X_test = test[['Open', 'Close', 'Volume', 'Open_Close_diff', 'Volume_squared']]\n",
    "\n",
    "# Making predictions on the 'test' data\n",
    "y_pred_test = voting_classifier.predict(X_test)\n",
    "\n",
    "# Inverse transforming the encoded predictions to their original labels for 'test' data\n",
    "y_pred_test = label_encoder.inverse_transform(y_pred_test)\n",
    "\n",
    "# Adding predicted strategies to the 'test' DataFrame\n",
    "test['Predicted_Strategy'] = y_pred_test\n",
    "\n",
    "# Creating a submission DataFrame for the final predictions\n",
    "submission = pd.DataFrame()\n",
    "submission[\"id\"] = test[\"id\"]\n",
    "submission[\"Date\"] = test[\"Date\"]\n",
    "submission[\"Close\"] = test[\"Close\"]\n",
    "submission[\"Strategy\"] = test[\"Predicted_Strategy\"]\n",
    "\n",
    "# Displaying the first few rows of the submission DataFrame\n",
    "submission.head()\n",
    "\n",
    "# Saving the submission DataFrame to a CSV file\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 112.276152,
   "end_time": "2023-11-04T12:22:56.112334",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-11-04T12:21:03.836182",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
